{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2BVH_JD9WiA"
   },
   "source": [
    "Below we will try and fit a Logisitc Regression Model step by step for the XOR problem.\n",
    "Fill in the code where there is a `_FILL_` specified. For this model, we have $x_1$ and $x_2$ are either 0/1 each and $y = x_1 + x_2 - 2x_1x_2$. Notice that this is True (1) if $x_1 = 1$ and $x_2 = 0$ OR $x_1 = 0$ and $x_2 = 1$; $y$ is zero otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wiFGf-9H9X3d"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1TRwUp469X-r"
   },
   "outputs": [],
   "source": [
    "x_data = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "y_data = [[0], [1], [1], [0]]\n",
    "x_data = torch.Tensor(x_data)\n",
    "y_data = torch.Tensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2FJM6ckGBRz_"
   },
   "outputs": [],
   "source": [
    "# Define each tensor to be 1x1 and have them require a gradient for tracking; these are parameters\n",
    "alpha = torch.rand(1, requires_grad = True)\n",
    "beta_1 = torch.rand(1, requires_grad = True)\n",
    "beta_2 = torch.rand(1, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BToqdBCr9YBI",
    "outputId": "2d08fd64-23e5-4013-c407-14a5f9b1e4ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Loss: 0.7430764436721802 Accuracy: 0.5\n",
      "Epoch: 1\n",
      "Loss: 0.7417216300964355 Accuracy: 0.5\n",
      "Epoch: 2\n",
      "Loss: 0.7404038906097412 Accuracy: 0.5\n",
      "Epoch: 3\n",
      "Loss: 0.7391220331192017 Accuracy: 0.5\n",
      "Epoch: 4\n",
      "Loss: 0.7378755211830139 Accuracy: 0.5\n",
      "Epoch: 5\n",
      "Loss: 0.736663281917572 Accuracy: 0.5\n",
      "Epoch: 6\n",
      "Loss: 0.7354844808578491 Accuracy: 0.5\n",
      "Epoch: 7\n",
      "Loss: 0.7343384027481079 Accuracy: 0.5\n",
      "Epoch: 8\n",
      "Loss: 0.7332241535186768 Accuracy: 0.5\n",
      "Epoch: 9\n",
      "Loss: 0.7321408987045288 Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "\n",
    "for epoch in range(10):\n",
    "  for x, y in zip(x_data, y_data):\n",
    "\n",
    "    # Have z be beta_2*x[0] + beta_1*x[1] + alpha\n",
    "    z = beta_2 * x[0] + beta_1 * x[1] + alpha\n",
    "\n",
    "    # Push z through a nn.Sigmoid layer to get the p(y=1)\n",
    "    a = nn.Sigmoid()(z)\n",
    "\n",
    "    # Write the loss manually between y and a\n",
    "    loss = -y * torch.log(a) - (1 - y) * torch.log(1 - a)\n",
    "\n",
    "    # Get the loss gradients; the gradients with respect to alpha, beta_1, beta_2\n",
    "    loss.backward()\n",
    "\n",
    "    # Manually update the gradients\n",
    "    # What we do below is wrapped within this clause because weights have required_grad=True but we don't need to track this in autograd\n",
    "    with torch.no_grad():\n",
    "        # Do an update for each parameter\n",
    "        alpha -= lr * alpha.grad\n",
    "        beta_1 -= lr * beta_1.grad\n",
    "        beta_2 -= lr * beta_2.grad\n",
    "\n",
    "        # Manually zero the gradients after updating weights\n",
    "        alpha.grad = None\n",
    "        beta_1.grad = None\n",
    "        beta_2.grad = None\n",
    "\n",
    "  # Manually get the accuracy of the model after each epoch\n",
    "  with torch.no_grad():\n",
    "    print(f'Epoch: {epoch}')\n",
    "    y_pred = []\n",
    "    loss = 0.0\n",
    "\n",
    "    for x, y in zip(x_data, y_data):\n",
    "      # Get z\n",
    "      z = beta_2 * x[0] + beta_1 * x[1] + alpha\n",
    "\n",
    "      # Get a\n",
    "      a = nn.Sigmoid()(z)\n",
    "\n",
    "      # Get the loss\n",
    "      loss += (-y * torch.log(a) - (1 - y) * torch.log(1 - a)) / 4\n",
    "\n",
    "      # Get the prediction given a\n",
    "      y_pred.append(1 if a.item() > 0.5 else 0)\n",
    "\n",
    "    # Get the current accuracy over 4 points\n",
    "    y_pred = torch.tensor(y_pred)\n",
    "\n",
    "    accuracy = (y_pred == y_data.squeeze()).sum() / 4\n",
    "\n",
    "    # Print the accuracy and the loss\n",
    "    print('Loss: {} Accuracy: {}'.format(loss.item(), accuracy.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "utB42M0p_bpZ",
    "outputId": "e493da05-d526-46fa-b9d2-ef07c00da03e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1729.8634033203125\n",
      "199 1205.185791015625\n",
      "299 841.1913452148438\n",
      "399 588.433349609375\n",
      "499 412.75860595703125\n",
      "599 290.5504455566406\n",
      "699 205.4640655517578\n",
      "799 146.17465209960938\n",
      "899 104.82827758789062\n",
      "999 75.97254180908203\n",
      "1099 55.819454193115234\n",
      "1199 41.734344482421875\n",
      "1299 31.883529663085938\n",
      "1399 24.989667892456055\n",
      "1499 20.162181854248047\n",
      "1599 16.779708862304688\n",
      "1699 14.408369064331055\n",
      "1799 12.745028495788574\n",
      "1899 11.577713966369629\n",
      "1999 10.758106231689453\n",
      "Result: y = 0.04442664608359337 + 0.8437238931655884 x + -0.007664335425943136 x^2 + -0.09147883951663971 x^3\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "dtype = torch.float\n",
    "\n",
    "# Create Tensors to hold input and outputs.\n",
    "# By default, requires_grad=False, which indicates that we do not need to\n",
    "# compute gradients with respect to these Tensors during the backward pass.\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Create random Tensors for weights. For a third order polynomial, we need\n",
    "# 4 weights: y = a + b x + c x^2 + d x^3\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these Tensors during the backward pass.\n",
    "a = torch.randn((), dtype=dtype, requires_grad=True)\n",
    "b = torch.randn((), dtype=dtype, requires_grad=True)\n",
    "c = torch.randn((), dtype=dtype, requires_grad=True)\n",
    "d = torch.randn((), dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y using operations on Tensors.\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss using operations on Tensors.\n",
    "    # Now loss is a Tensor of shape (1,)\n",
    "    # loss.item() gets the scalar value held in the loss.\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Use autograd to compute the backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Tensors with requires_grad=True.\n",
    "    # After this call a.grad, b.grad. c.grad and d.grad will be Tensors holding\n",
    "    # the gradient of the loss with respect to a, b, c, d respectively.\n",
    "    loss.backward()\n",
    "\n",
    "    # Manually update weights using gradient descent. Wrap in torch.no_grad()\n",
    "    # because weights have requires_grad=True, but we don't need to track this\n",
    "    # in autograd.\n",
    "    with torch.no_grad():\n",
    "        a -= learning_rate * a.grad\n",
    "        b -= learning_rate * b.grad\n",
    "        c -= learning_rate * c.grad\n",
    "        d -= learning_rate * d.grad\n",
    "\n",
    "        # Manually zero the gradients after updating weights\n",
    "        a.grad = None\n",
    "        b.grad = None\n",
    "        c.grad = None\n",
    "        d.grad = None\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iojtw_rFAjhY"
   },
   "source": [
    "Application 1: Create a 2D tensor and then add a dimension of size 1 inserted at the 0th axis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fgdImVPpAm6d",
    "outputId": "9a3d2ea6-8f33-4fd7-adfe-b7b7c09ecf82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0977, 0.6405, 0.2197],\n",
       "         [0.0076, 0.6612, 0.6541]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 3)\n",
    "x.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0yfuo7fAneJ"
   },
   "source": [
    "Exercise 2: Remove the extra dimension you just added to the previous tensor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "goe1-DBRAnnj",
    "outputId": "499138aa-f429-474a-e8af-53e34add8b1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0977, 0.6405, 0.2197],\n",
       "        [0.0076, 0.6612, 0.6541]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oAhtAtk5Any4"
   },
   "source": [
    "Exercise 3: Create a random tensor of shape 5x3 in the interval [3, 7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZCcFowEjAn8w",
    "outputId": "6b2553d5-b139-419d-d845-a8c535b303cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.4375, 4.0747, 3.0686],\n",
       "        [6.2739, 4.4818, 4.2337],\n",
       "        [5.4632, 4.4997, 4.3507],\n",
       "        [6.2013, 6.9733, 4.5900],\n",
       "        [4.2644, 3.3225, 5.2225]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5, 3) * 4 + 3\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvNprVRlAoEC"
   },
   "source": [
    "Exercise 4: Create a tensor with values from a normal distribution (mean=0, std=1).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Dgirc4kGAoKa"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1nIIGp8AoQL"
   },
   "source": [
    "exercise 5: Retrieve the indexes of all the non zero elements in the tensor torch.Tensor([1, 1, 1, 0, 1]).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sCv5zbq3AoV-",
    "outputId": "9942ce9c-c763-49e0-93c2-b6baf7d81333"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [4]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([1, 1, 1, 0, 1])\n",
    "x.nonzero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckErX5U1Aocz"
   },
   "source": [
    "Exercise 6: Create a random tensor of size (3,1) and then horizonally stack 4 copies together.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9D3XYAnoAoig",
    "outputId": "2554e44d-f170-4b09-e966-1e25b54b4322"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1503, 0.1503, 0.1503, 0.1503],\n",
       "        [0.7086, 0.7086, 0.7086, 0.7086],\n",
       "        [0.3414, 0.3414, 0.3414, 0.3414]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3, 1)\n",
    "x.repeat(1, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKV3ChJrAopD"
   },
   "source": [
    "Exercise 7: Return the batch matrix-matrix product of two 3 dimensional matrices (a=torch.rand(3,4,5), b=torch.rand(3,5,4)).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ge6IErGdAovX",
    "outputId": "dd39067a-72d2-42e8-b955-7aa783e626ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.6394, 0.6833, 1.5837, 1.5976],\n",
       "         [1.1472, 0.3890, 1.0009, 1.2655],\n",
       "         [1.0815, 0.5244, 1.0628, 1.4311],\n",
       "         [1.9040, 1.2040, 1.4985, 1.4086]],\n",
       "\n",
       "        [[0.9391, 1.2059, 1.3412, 0.8154],\n",
       "         [1.3120, 1.4383, 1.8123, 1.1125],\n",
       "         [0.5450, 1.4864, 1.3260, 0.6719],\n",
       "         [0.6573, 1.7938, 1.7714, 1.0374]],\n",
       "\n",
       "        [[0.9832, 0.5582, 1.1056, 1.0532],\n",
       "         [1.9757, 1.1756, 2.0718, 1.7928],\n",
       "         [1.2413, 0.8302, 1.0994, 0.5718],\n",
       "         [1.7323, 0.9673, 1.6841, 1.2645]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3, 4, 5)\n",
    "y = torch.rand(3, 5, 4)\n",
    "torch.bmm(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qVI_LI_PA_2e"
   },
   "source": [
    "Exercise 8: Return the batch matrix-matrix product of a 3D matrix and a 2D matrix (a=torch.rand(3,4,5), b=torch.rand(5,4)).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kpLgovtyBAA6",
    "outputId": "5ec0cb93-d699-46af-dbfa-e76e104da8ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3375, 0.2907, 0.3181, 0.1812],\n",
       "         [1.1075, 1.0032, 1.0962, 1.0600],\n",
       "         [1.4107, 1.2923, 1.7551, 1.4518],\n",
       "         [1.1264, 0.7016, 1.4619, 0.9141]],\n",
       "\n",
       "        [[1.1713, 0.7899, 1.4845, 0.5677],\n",
       "         [1.5807, 1.1571, 1.4543, 1.1874],\n",
       "         [1.3340, 0.9715, 1.3254, 0.9939],\n",
       "         [1.3030, 0.6757, 1.9461, 1.0246]],\n",
       "\n",
       "        [[0.9775, 0.8165, 1.1316, 0.9601],\n",
       "         [0.9570, 0.9399, 0.8771, 0.8693],\n",
       "         [0.9590, 0.6913, 0.9538, 0.7193],\n",
       "         [1.1810, 0.8096, 1.4295, 1.1040]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3, 4, 5)\n",
    "y = torch.rand(5, 4)\n",
    "torch.bmm(x, y.unsqueeze(0).expand(x.size(0), *y.size()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KW6NxQIeBAJA"
   },
   "source": [
    "Exercise 9: Create a 1x1 random tensor and get the value inside of this tensor as a scalar. No tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o_OFj9hEBAPO",
    "outputId": "32349d97-a959-419a-aa3d-1da4e29e65ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31901270151138306"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 1)\n",
    "x.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_zAwiqrBAVd"
   },
   "source": [
    "Exercise 10: Create a 2x1 tensor and have it require a gradient. Have $x$, this tensor, hold [-2, 1]. Set $y=x_1^2 + x_2^2$ and get the gradient of y wirht respect to $x_1$ and then $x_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z98hDPfEBAcv",
    "outputId": "2c683c02-4f3b-4ddd-d820-d986b68d2fc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7460],\n",
       "        [0.3626]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 1, requires_grad=True)\n",
    "y = x[0] ** 2 + x[1] ** 2\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGfmkpF3BAjy"
   },
   "source": [
    "Exercise 11: Check if cuda is available (it shuld be if in the Runtime setting for colab you choose the GPU). If it is, move $x$ above to a CUDA device. Create a new tensor of the same shape as $x$ and put it on the cpu. Try and add these tensors. What happens. How do you fix this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "2M_Suz2XBAsX",
    "outputId": "ab952026-83ce-4a6c-a6db-59d4cd4e4081"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-75bee63a3e4f>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 1, requires_grad=True)\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "y = torch.randn(2, 1)\n",
    "y = y.cpu()\n",
    "y + x\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
